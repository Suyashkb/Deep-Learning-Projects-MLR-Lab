{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":408382,"sourceType":"datasetVersion","datasetId":181847},{"sourceId":7438735,"sourceType":"datasetVersion","datasetId":4329451},{"sourceId":8626785,"sourceType":"datasetVersion","datasetId":5164853}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\"\"\"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\"\"\"\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T20:13:11.332818Z","iopub.execute_input":"2024-06-06T20:13:11.333634Z","iopub.status.idle":"2024-06-06T20:13:12.396321Z","shell.execute_reply.started":"2024-06-06T20:13:11.333602Z","shell.execute_reply":"2024-06-06T20:13:12.395420Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"import os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\""},"metadata":{}}]},{"cell_type":"code","source":"sea_boat_train='/kaggle/input/boat-vs-sea-images-dataset'\nbus_car_train='/kaggle/input/object-detection/Training_set/Training_set'\n\nbus_car_val='/kaggle/input/object-detection/test/test'\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:13:12.398376Z","iopub.execute_input":"2024-06-06T20:13:12.399079Z","iopub.status.idle":"2024-06-06T20:13:12.403570Z","shell.execute_reply.started":"2024-06-06T20:13:12.399046Z","shell.execute_reply":"2024-06-06T20:13:12.402512Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\ndef create_dataset(path,l_mode='binary',img_size=(128,128)):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(path,labels='inferred', label_mode=l_mode,batch_size=32,image_size=img_size,shuffle=True,seed=123)\n    \n    def normalize(image, label):\n        image = tf.cast(image, tf.float32) / 255.0\n        return image, label\n\n    dataset_final=dataset.map(normalize)\n    return dataset_final\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:13:28.444316Z","iopub.execute_input":"2024-06-06T20:13:28.444687Z","iopub.status.idle":"2024-06-06T20:13:40.262064Z","shell.execute_reply.started":"2024-06-06T20:13:28.444649Z","shell.execute_reply":"2024-06-06T20:13:40.261226Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-06 20:13:30.188961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 20:13:30.189085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 20:13:30.319730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_sb= create_dataset(sea_boat_train)\n\ntraindata_cb=create_dataset(bus_car_train)\nvaldata_cb=create_dataset(bus_car_val)\n\ntrain_size = int(0.8 * len(dataset_sb))\nval_size = len(dataset_sb) - train_size\n\ntraindata_sb = dataset_sb.take(train_size)\nvaldata_sb = dataset_sb.skip(train_size)\n\nfor image, label in traindata_sb.take(1):\n    print(f\"Image shape: {image.shape}, Label: {label}\")\n ","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:14:10.168724Z","iopub.execute_input":"2024-06-06T20:14:10.169326Z","iopub.status.idle":"2024-06-06T20:14:13.550661Z","shell.execute_reply.started":"2024-06-06T20:14:10.169294Z","shell.execute_reply":"2024-06-06T20:14:13.549678Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 2000 files belonging to 2 classes.\nFound 1486 files belonging to 2 classes.\nFound 382 files belonging to 2 classes.\nImage shape: (32, 128, 128, 3), Label: [[1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(traindata_sb))\nprint(len(valdata_sb))\nprint(len(traindata_cb))\nprint(len(valdata_cb))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:14:13.552352Z","iopub.execute_input":"2024-06-06T20:14:13.552690Z","iopub.status.idle":"2024-06-06T20:14:13.559286Z","shell.execute_reply.started":"2024-06-06T20:14:13.552664Z","shell.execute_reply":"2024-06-06T20:14:13.557814Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"50\n13\n47\n12\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_new_label(dataset, new_label):\n    # Map function to add a new label to each image in the dataset\n    def add_label(image, label):\n        image = tf.cast(image, tf.float32) / 255.0  # Normalize the image\n        new_label_tensor = tf.constant(new_label, dtype=tf.int64)\n        new_label_tensor = tf.expand_dims(label, axis=-1) \n        return image, new_label_tensor\n    return dataset.map(add_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:14:14.669912Z","iopub.execute_input":"2024-06-06T20:14:14.670253Z","iopub.status.idle":"2024-06-06T20:14:14.676326Z","shell.execute_reply.started":"2024-06-06T20:14:14.670227Z","shell.execute_reply":"2024-06-06T20:14:14.675303Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndef train_model_sb(train_data,val_data,epochs=10):\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n    val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n    \n    model = tf.keras.Sequential([\n        layers.Input(shape=(128, 128, 3)),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(256, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.4),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(1, activation='sigmoid')  # 1 output neuron for binary classification\n    ])\n    \n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',  # Use binary cross-entropy loss for binary classification\n                  metrics=['accuracy'])\n\n    # Train the model\n    model.fit(train_data, validation_data=val_data, epochs=epochs)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:15:05.029820Z","iopub.execute_input":"2024-06-06T20:15:05.030221Z","iopub.status.idle":"2024-06-06T20:15:05.040628Z","shell.execute_reply.started":"2024-06-06T20:15:05.030189Z","shell.execute_reply":"2024-06-06T20:15:05.039693Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sea_boat_classifier=train_model_sb(traindata_sb,valdata_sb,30)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:15:12.615277Z","iopub.execute_input":"2024-06-06T20:15:12.616146Z","iopub.status.idle":"2024-06-06T20:16:23.564745Z","shell.execute_reply.started":"2024-06-06T20:15:12.616111Z","shell.execute_reply":"2024-06-06T20:16:23.563781Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m 5/50\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4248 - loss: 1.6313 ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717704929.943486     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717704929.962885     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5417 - loss: 0.9342","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717704937.241155     114 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 202ms/step - accuracy: 0.5457 - loss: 0.9247 - val_accuracy: 0.8000 - val_loss: 0.4860\nEpoch 2/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7805 - loss: 0.5006 - val_accuracy: 0.8150 - val_loss: 0.4105\nEpoch 3/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8070 - loss: 0.4448 - val_accuracy: 0.8275 - val_loss: 0.3946\nEpoch 4/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8242 - loss: 0.4028 - val_accuracy: 0.8450 - val_loss: 0.3727\nEpoch 5/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8274 - loss: 0.3922 - val_accuracy: 0.8375 - val_loss: 0.3843\nEpoch 6/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8405 - loss: 0.3723 - val_accuracy: 0.8325 - val_loss: 0.3816\nEpoch 7/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8337 - loss: 0.3851 - val_accuracy: 0.8550 - val_loss: 0.3406\nEpoch 8/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8652 - loss: 0.3274 - val_accuracy: 0.8650 - val_loss: 0.3548\nEpoch 9/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8796 - loss: 0.3214 - val_accuracy: 0.8825 - val_loss: 0.3130\nEpoch 10/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8685 - loss: 0.3192 - val_accuracy: 0.8350 - val_loss: 0.4586\nEpoch 11/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8743 - loss: 0.3318 - val_accuracy: 0.8850 - val_loss: 0.3269\nEpoch 12/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8864 - loss: 0.2887 - val_accuracy: 0.8975 - val_loss: 0.3132\nEpoch 13/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8981 - loss: 0.2766 - val_accuracy: 0.8625 - val_loss: 0.3510\nEpoch 14/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8617 - loss: 0.3324 - val_accuracy: 0.8800 - val_loss: 0.3362\nEpoch 15/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8990 - loss: 0.2716 - val_accuracy: 0.8925 - val_loss: 0.3467\nEpoch 16/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9105 - loss: 0.2365 - val_accuracy: 0.8975 - val_loss: 0.3568\nEpoch 17/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9124 - loss: 0.2421 - val_accuracy: 0.8975 - val_loss: 0.3227\nEpoch 18/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9145 - loss: 0.2315 - val_accuracy: 0.9000 - val_loss: 0.3612\nEpoch 19/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9148 - loss: 0.2289 - val_accuracy: 0.8850 - val_loss: 0.3595\nEpoch 20/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9138 - loss: 0.2321 - val_accuracy: 0.8900 - val_loss: 0.3329\nEpoch 21/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9185 - loss: 0.2214 - val_accuracy: 0.8975 - val_loss: 0.3494\nEpoch 22/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9238 - loss: 0.2058 - val_accuracy: 0.8975 - val_loss: 0.3633\nEpoch 23/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9320 - loss: 0.1913 - val_accuracy: 0.9025 - val_loss: 0.3774\nEpoch 24/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9332 - loss: 0.1809 - val_accuracy: 0.8975 - val_loss: 0.4053\nEpoch 25/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9341 - loss: 0.1703 - val_accuracy: 0.9100 - val_loss: 0.3959\nEpoch 26/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9285 - loss: 0.1851 - val_accuracy: 0.8925 - val_loss: 0.4067\nEpoch 27/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9392 - loss: 0.1554 - val_accuracy: 0.8950 - val_loss: 0.3985\nEpoch 28/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9552 - loss: 0.1288 - val_accuracy: 0.9125 - val_loss: 0.4192\nEpoch 29/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9647 - loss: 0.1059 - val_accuracy: 0.9075 - val_loss: 0.4359\nEpoch 30/30\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9602 - loss: 0.1029 - val_accuracy: 0.8925 - val_loss: 0.4682\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\ndef train_model_cb(train_data,val_data,epochs=10):\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n    val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n    \n    model = tf.keras.Sequential([\n        layers.Input(shape=(128, 128, 3)),\n        layers.Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.4),\n        layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n        layers.MaxPooling2D((2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.4),\n        layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dense(1, activation='sigmoid')  # 1 output neuron for binary classification\n    ])\n    \n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',  # Use binary cross-entropy loss for binary classification\n                  metrics=['accuracy'])\n\n    # Train the model\n    model.fit(train_data, validation_data=val_data, epochs=epochs)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:57:45.224051Z","iopub.execute_input":"2024-06-06T20:57:45.224418Z","iopub.status.idle":"2024-06-06T20:57:45.235741Z","shell.execute_reply.started":"2024-06-06T20:57:45.224377Z","shell.execute_reply":"2024-06-06T20:57:45.234753Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"car_bus_classifier=train_model_cb(traindata_cb,valdata_cb,30)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T20:57:46.377834Z","iopub.execute_input":"2024-06-06T20:57:46.378556Z","iopub.status.idle":"2024-06-06T20:58:20.783153Z","shell.execute_reply.started":"2024-06-06T20:57:46.378522Z","shell.execute_reply":"2024-06-06T20:58:20.782210Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.5698 - loss: 1.2071 - val_accuracy: 0.7592 - val_loss: 0.7840\nEpoch 2/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7884 - loss: 0.6879 - val_accuracy: 0.8246 - val_loss: 0.6545\nEpoch 3/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8598 - loss: 0.5394 - val_accuracy: 0.8298 - val_loss: 0.5614\nEpoch 4/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8691 - loss: 0.4704 - val_accuracy: 0.8560 - val_loss: 0.5404\nEpoch 5/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8633 - loss: 0.4660 - val_accuracy: 0.8665 - val_loss: 0.4701\nEpoch 6/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8881 - loss: 0.3855 - val_accuracy: 0.9162 - val_loss: 0.3912\nEpoch 7/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9365 - loss: 0.3160 - val_accuracy: 0.8901 - val_loss: 0.4029\nEpoch 8/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9363 - loss: 0.2980 - val_accuracy: 0.8901 - val_loss: 0.3826\nEpoch 9/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9363 - loss: 0.2836 - val_accuracy: 0.8953 - val_loss: 0.3633\nEpoch 10/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9368 - loss: 0.2889 - val_accuracy: 0.9188 - val_loss: 0.3656\nEpoch 11/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9515 - loss: 0.2677 - val_accuracy: 0.8927 - val_loss: 0.3795\nEpoch 12/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9575 - loss: 0.2429 - val_accuracy: 0.9031 - val_loss: 0.3508\nEpoch 13/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9534 - loss: 0.2460 - val_accuracy: 0.9162 - val_loss: 0.3347\nEpoch 14/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9429 - loss: 0.2390 - val_accuracy: 0.9110 - val_loss: 0.3731\nEpoch 15/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9590 - loss: 0.2202 - val_accuracy: 0.9188 - val_loss: 0.3307\nEpoch 16/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9722 - loss: 0.1941 - val_accuracy: 0.9241 - val_loss: 0.3149\nEpoch 17/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9759 - loss: 0.1847 - val_accuracy: 0.9267 - val_loss: 0.3523\nEpoch 18/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9621 - loss: 0.2097 - val_accuracy: 0.9319 - val_loss: 0.3452\nEpoch 19/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9807 - loss: 0.1719 - val_accuracy: 0.9110 - val_loss: 0.3870\nEpoch 20/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.1822 - val_accuracy: 0.9058 - val_loss: 0.3510\nEpoch 21/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9679 - loss: 0.1904 - val_accuracy: 0.8901 - val_loss: 0.3948\nEpoch 22/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9837 - loss: 0.1838 - val_accuracy: 0.9215 - val_loss: 0.3444\nEpoch 23/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9811 - loss: 0.1696 - val_accuracy: 0.9372 - val_loss: 0.3425\nEpoch 24/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9808 - loss: 0.1574 - val_accuracy: 0.8979 - val_loss: 0.4258\nEpoch 25/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9713 - loss: 0.1990 - val_accuracy: 0.9529 - val_loss: 0.3167\nEpoch 26/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9783 - loss: 0.1759 - val_accuracy: 0.8979 - val_loss: 0.4345\nEpoch 27/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9777 - loss: 0.1795 - val_accuracy: 0.9136 - val_loss: 0.4505\nEpoch 28/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9911 - loss: 0.1393 - val_accuracy: 0.9450 - val_loss: 0.3124\nEpoch 29/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9792 - loss: 0.1645 - val_accuracy: 0.9424 - val_loss: 0.3002\nEpoch 30/30\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9834 - loss: 0.1605 - val_accuracy: 0.9503 - val_loss: 0.3103\n","output_type":"stream"}]},{"cell_type":"code","source":"def replace_labels_with_one(image, label):\n    label = tf.constant(1, dtype=tf.int32)\n    label = tf.expand_dims(label, axis=-1)\n    return image,label\n\ndef replace_labels_with_zero(image, label):\n    label = tf.constant(0, dtype=tf.int32)\n    label = tf.expand_dims(label, axis=-1)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:32:17.965509Z","iopub.execute_input":"2024-06-06T21:32:17.966180Z","iopub.status.idle":"2024-06-06T21:32:17.971789Z","shell.execute_reply.started":"2024-06-06T21:32:17.966152Z","shell.execute_reply":"2024-06-06T21:32:17.970818Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_data_g1 = traindata_sb.map(replace_labels_with_one)\nval_data_g1 = valdata_sb.map(replace_labels_with_one)\n\ntrain_data_g2=traindata_cb.map(replace_labels_with_zero)\nval_data_g2=valdata_cb.map(replace_labels_with_zero)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:32:20.333939Z","iopub.execute_input":"2024-06-06T21:32:20.334291Z","iopub.status.idle":"2024-06-06T21:32:20.455645Z","shell.execute_reply.started":"2024-06-06T21:32:20.334262Z","shell.execute_reply":"2024-06-06T21:32:20.454715Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_data_g1.take(2):\n    print(labels.numpy())\nfor images, labels in train_data_g2.take(2):\n    print(labels.numpy())\nfor images, labels in val_data_g1.take(2):\n    print(labels.numpy())\nfor images, labels in val_data_g2.take(2):\n    print(labels.numpy())","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:32:20.751093Z","iopub.execute_input":"2024-06-06T21:32:20.751936Z","iopub.status.idle":"2024-06-06T21:32:26.104916Z","shell.execute_reply.started":"2024-06-06T21:32:20.751902Z","shell.execute_reply":"2024-06-06T21:32:26.103975Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"[1]\n[1]\n[0]\n[0]\n[1]\n[1]\n[0]\n[0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_groups=train_data_g1.concatenate(train_data_g2)\nval_data_groups=val_data_g1.concatenate(val_data_g2)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:32:30.905805Z","iopub.execute_input":"2024-06-06T21:32:30.906171Z","iopub.status.idle":"2024-06-06T21:32:30.914059Z","shell.execute_reply.started":"2024-06-06T21:32:30.906140Z","shell.execute_reply":"2024-06-06T21:32:30.913164Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint(len(train_data_groups))\nprint(len(val_data_groups))\nfor images, labels in train_data_groups.skip(50):\n    print(f\"Image shape: {images.shape}, Label shape: {labels.shape}\")\n    \n    for i in range (0,2):\n        plt.imshow(images[i]) \n        plt.axis('off')  \n        plt.show()\n        print(labels)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train_model_group(train_data,val_data,epochs=10):\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n    val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n    \n    model = tf.keras.Sequential([\n        layers.Input(shape=(128, 128, 3)),\n        layers.Conv2D(128, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(256, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(512, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.4),\n        layers.Dense(256, activation='relu'),\n        layers.Dense(1, activation='sigmoid')  \n    ])\n    \n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',  \n                  metrics=['accuracy'])\n\n    # Train the model\n    model.fit(train_data, validation_data=val_data, epochs=epochs)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:44:32.617220Z","iopub.execute_input":"2024-06-06T21:44:32.618158Z","iopub.status.idle":"2024-06-06T21:44:32.626629Z","shell.execute_reply.started":"2024-06-06T21:44:32.618123Z","shell.execute_reply":"2024-06-06T21:44:32.625741Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"group_classifier=train_model_group(train_data_groups,val_data_groups,10)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T21:44:39.387422Z","iopub.execute_input":"2024-06-06T21:44:39.387783Z","iopub.status.idle":"2024-06-06T21:46:50.021647Z","shell.execute_reply.started":"2024-06-06T21:44:39.387757Z","shell.execute_reply":"2024-06-06T21:46:50.020804Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 369ms/step - accuracy: 0.4506 - loss: 2.5103 - val_accuracy: 0.8171 - val_loss: 0.4550\nEpoch 2/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.8362 - loss: 0.3506 - val_accuracy: 0.8223 - val_loss: 0.3413\nEpoch 3/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.8920 - loss: 0.2381 - val_accuracy: 0.9079 - val_loss: 0.2373\nEpoch 4/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.9271 - loss: 0.1842 - val_accuracy: 0.9054 - val_loss: 0.2456\nEpoch 5/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - accuracy: 0.9259 - loss: 0.1818 - val_accuracy: 0.9092 - val_loss: 0.2017\nEpoch 6/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.9478 - loss: 0.1370 - val_accuracy: 0.9309 - val_loss: 0.1544\nEpoch 7/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.9498 - loss: 0.1228 - val_accuracy: 0.9028 - val_loss: 0.2535\nEpoch 8/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.9522 - loss: 0.1274 - val_accuracy: 0.9463 - val_loss: 0.1297\nEpoch 9/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.9729 - loss: 0.0773 - val_accuracy: 0.9386 - val_loss: 0.1447\nEpoch 10/10\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.9728 - loss: 0.0646 - val_accuracy: 0.9476 - val_loss: 0.1343\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\n\ndef load_and_preprocess_image(image_path, target_size=(128, 128)):\n    \"\"\"Load an image from a file path and preprocess it for prediction.\"\"\"\n    img = load_img(image_path, target_size=target_size)\n    img_array = img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0  # Normalize to [0, 1]\n    return img_array\n\ndef get_prediction(image_path):\n    \"\"\"Predict the class of the image given its file path.\"\"\"\n    # Load and preprocess the image\n    img_array = load_and_preprocess_image(image_path)\n    \n    # Predict the group\n    group_prediction = group_classifier.predict(img_array)\n    \n    if group_prediction > 0.5:\n        print(\"Classifying within Group 1 (Sea or Boat Category)\")\n        final_prediction = sea_boat_classifier.predict(img_array)\n        final_class = \"This is a Boat (Object 1)\" if final_prediction < 0.5 else \"This is an image of a Sea (Object 2)\"\n    else:\n        print(\"Classifying within Group 2 (Car or Bus Category)\")\n        final_prediction = car_bus_classifier.predict(img_array)\n        final_class = \"This is a Bus (Object 3)\" if final_prediction < 0.5 else \"This is a Car (Object 4)\"\n    \n    return final_class\n\n# Example usage:\n# Assuming 'group_classifier', 'model_group_1', and 'model_group_2' are already loaded and initialized models.\nimage_path = \"/kaggle/input/sea-image/image.jpeg\"\nprediction = get_prediction(image_path)\nprint(prediction)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T22:01:38.815500Z","iopub.execute_input":"2024-06-06T22:01:38.815882Z","iopub.status.idle":"2024-06-06T22:01:39.921328Z","shell.execute_reply.started":"2024-06-06T22:01:38.815853Z","shell.execute_reply":"2024-06-06T22:01:39.920246Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nClassifying within Group 1 (Sea or Boat Category)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863ms/step\nThis is an image of a Sea (Object 2)\n","output_type":"stream"}]}]}